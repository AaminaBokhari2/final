#!/usr/bin/env python3
"""
FastAPI Backend for AI Study Assistant - GROQ VERSION
This version uses Groq API instead of OpenAI
"""

from fastapi import FastAPI, UploadFile, File, HTTPException, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import tempfile
import os
from typing import List, Dict, Optional
import json
import asyncio
import logging
from pydantic import BaseModel
import time

from pipeline import AIPresentationCoordinatorAgent




# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import your existing classes and newly integrated slidesmaker classes
try:
  from pipeline import (
      GroqClient, EnhancedPDFProcessor, SummaryAgent, 
      FlashcardAgent, QuizAgent, AIEnhancedResearchDiscoveryAgent, 
      AIEnhancedYouTubeDiscoveryAgent, AIEnhancedWebResourceAgent,QAChatbotAgent ,AIPresentationCoordinatorAgent
       
  )
  coordinator_agent = AIPresentationCoordinatorAgent("credentials.json")
  logger.info("‚úÖ Successfully imported pipeline modules")
except ImportError as e:
  logger.error(f"‚ùå Failed to import pipeline modules: {e}")
  raise

# Initialize FastAPI app
app = FastAPI(
  title="AI Study Assistant API",
  description="Backend API for AI-powered study material generation",
  version="1.0.0"
)

app.add_middleware(
  CORSMiddleware,
  allow_origins=[
      "http://localhost:3000",
      "http://localhost:5173", 
      "https://psychic-yodel-77vv4g95qg6crv9g-5173.app.github.dev",  # Your frontend
      "https://psychic-yodel-77vv4g95qg6crv9g-5173.app.github.dev/", # With trailing slash
      "https://*.app.github.dev",  # Wildcard for all codespaces
  ],
  allow_credentials=False,
  allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
  allow_headers=["*"],
)

# Pydantic models for API responses
class ProcessingStatus(BaseModel):
  status: str
  message: str
  word_count: int
  page_count: int
  methods_used: List[str]

class SummaryResponse(BaseModel):
  summary: str
  status: str
  fallback_used: bool = False

class FlashcardResponse(BaseModel):
  flashcards: List[Dict]
  count: int
  status: str
  fallback_used: bool = False

class QuizResponse(BaseModel):
  quiz: List[Dict]
  count: int
  status: str
  fallback_used: bool = False

class ResearchPapersResponse(BaseModel):
  papers: List[Dict]
  count: int
  status: str

class VideosResponse(BaseModel):
  videos: List[Dict]
  count: int
  status: str

class WebResourcesResponse(BaseModel):
  resources: List[Dict]
  count: int
  status: str

class QuestionRequest(BaseModel):
  question: str
  document_text: str

class AnswerResponse(BaseModel):
  answer: str
  status: str
  fallback_used: bool = False

class ApiStatusResponse(BaseModel):
  api_available: bool
  quota_status: str
  message: str
  fallback_enabled: bool

# Pydantic models for Slidesmaker feature
class SlideContentResponse(BaseModel):
  title: str
  content: List[str]
  slide_type: str
  notes: str = ""

class PresentationResponse(BaseModel):
  title: str
  slides: List[SlideContentResponse]
  theme: str
  total_slides: int

class DesignGuidelinesResponse(BaseModel):
  color_scheme: List[str]
  fonts: Dict[str, str]
  layout: Dict[str, str]
  suggestions: str

class QualityAssessmentResponse(BaseModel):
  issues: List[str]
  suggestions: List[str]
  quality_assessment: str
  overall_score: int
  success: bool

class GeneratePresentationRequest(BaseModel):
  topic: str
  audience: str = "general"
  duration: int = 10
  theme: str = "professional"

class GeneratePresentationOutput(BaseModel):
  success: bool
  presentation: PresentationResponse
  design_guidelines: DesignGuidelinesResponse
  quality_assessment: QualityAssessmentResponse

# Global variables to store state
study_sessions = {}
api_status = {
  "available": False,
  "quota_exceeded": False,
  "last_check": 0,
  "consecutive_failures": 0
}

# Initialize agents with error handling
client = None
pdf_processor = None
summary_agent = None
flashcard_agent = None
quiz_agent = None
research_agent = None
youtube_agent = None
web_agent = None


def check_api_status():
  """Check Groq API status and update global status"""
  global api_status
  
  current_time = time.time()
  
  # Only check every 60 seconds to avoid spam
  if current_time - api_status["last_check"] < 60:
      return api_status["available"]
  
  try:
      if client:
          test_response = client.chat_completion(
              [{"role": "user", "content": "Test"}],
              max_tokens=5
          )
          
          if "‚ùå" in test_response:
              if "quota" in test_response.lower() or "429" in test_response:
                  api_status["quota_exceeded"] = True
                  api_status["available"] = False
                  api_status["consecutive_failures"] += 1
              else:
                  api_status["available"] = False
                  api_status["consecutive_failures"] += 1
          else:
              api_status["available"] = True
              api_status["quota_exceeded"] = False
              api_status["consecutive_failures"] = 0
      else:
          api_status["available"] = False
          
  except Exception as e:
      api_status["available"] = False
      api_status["consecutive_failures"] += 1
      logger.error(f"API status check failed: {e}")
  
  api_status["last_check"] = current_time
  
  # Log status changes
  if api_status["consecutive_failures"] > 0:
      logger.warning(f"‚ö†Ô∏è API issues detected. Consecutive failures: {api_status['consecutive_failures']}")
  
  return api_status["available"]

def generate_fallback_summary(text: str) -> str:
  """Generate a basic summary without AI when quota is exceeded"""
  if not text.strip():
      return "No content available to summarize."
  
  # Basic text analysis
  sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 20]
  words = text.split()
  word_count = len(words)
  
  # Extract first few sentences as summary
  summary_sentences = sentences[:5] if len(sentences) >= 5 else sentences
  
  summary = f"""## üìã DOCUMENT SUMMARY (Fallback Mode)

**Document Overview:**
This document contains approximately {word_count} words across multiple sections.

**Key Content (First Few Sentences):**
{'. '.join(summary_sentences[:3])}.

**Document Structure:**
- Total words: {word_count}
- Estimated reading time: {word_count // 200} minutes
- Content type: Academic/Professional material

**Study Recommendations:**
1. Read through the document systematically
2. Take notes on key concepts and definitions
3. Identify main themes and supporting arguments
4. Create your own questions for self-testing

*Note: This is a basic summary generated without AI assistance due to API limitations. For detailed analysis, please try again later when the AI service is available.*"""

  return summary

def generate_fallback_flashcards(text: str, num_cards: int = 10) -> List[Dict]:
  """Generate basic flashcards without AI when quota is exceeded"""
  if not text.strip() or len(text.split()) < 50:
      return []
  
  flashcards = []
  sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 30]
  
  # Extract key terms (simple heuristic)
  words = text.split()
  capitalized_words = [word for word in words if word[0].isupper() and len(word) > 3]
  
  # Create flashcards from sentences and key terms
  for i, sentence in enumerate(sentences[:num_cards]):
      if len(sentence) > 30:
          # Try to create a question from the sentence
          question = f"What does the document say about: {sentence[:50]}...?"
          
          flashcard = {
              'question': question,
              'answer': sentence,
              'difficulty': 'Basic',
              'category': 'Document Content',
              'hint': 'Review the document text carefully'
          }
          flashcards.append(flashcard)
  
  # Add some key term flashcards
  for term in capitalized_words[:num_cards - len(flashcards)]:
      if term not in [card['question'] for card in flashcards]:
          flashcard = {
              'question': f"What is {term}?",
              'answer': f"{term} is mentioned in the document as an important concept. Please refer to the document for detailed information.",
              'difficulty': 'Basic',
              'category': 'Key Terms',
              'hint': f'Look for {term} in the document'
          }
          flashcards.append(flashcard)
  
  return flashcards[:num_cards]

def generate_fallback_quiz(text: str, num_questions: int = 8) -> List[Dict]:
  """Generate basic quiz without AI when quota is exceeded"""
  if not text.strip() or len(text.split()) < 100:
      return []
  
  quiz_questions = []
  
  # Generate basic questions about the document
  word_count = len(text.split())
  sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 20]
  
  # Question 1: Document length
  quiz_questions.append({
      'question': 'Approximately how many words does this document contain?',
      'options': [
          f'About {word_count} words',
          f'About {word_count // 2} words', 
          f'About {word_count * 2} words',
          f'About {word_count // 3} words'
      ],
      'correct_answer': 0,
      'explanation': f'The document contains approximately {word_count} words.',
      'difficulty': 'Basic'
  })
  
  # Question 2: Content type
  quiz_questions.append({
      'question': 'What type of document is this most likely to be?',
      'options': [
          'Academic or professional material',
          'Fiction novel',
          'Recipe collection',
          'Shopping list'
      ],
      'correct_answer': 0,
      'explanation': 'Based on the content structure and complexity, this appears to be academic or professional material.',
      'difficulty': 'Basic'
  })
  
  # Generate questions from first few sentences
  for i, sentence in enumerate(sentences[:num_questions-2]):
      if len(sentence) > 40:
          quiz_questions.append({
              'question': 'According to the document, which statement is true?',
              'options': [
                  sentence[:60] + ('...' if len(sentence) > 60 else ''),
                  'This information is not mentioned in the document',
                  'The document states the opposite of this',
                  'This is only mentioned as a possibility'
              ],
              'correct_answer': 0,
              'explanation': f'The document states: {sentence}',
              'difficulty': 'Basic'
          })
          
          if len(quiz_questions) >= num_questions:
              break
  
  return quiz_questions[:num_questions]

@app.on_event("startup")
async def startup_event():
  """Initialize agents on startup with better error handling"""
  global client, pdf_processor, summary_agent, flashcard_agent, quiz_agent, research_agent, youtube_agent, web_agent, coordinator_agent
  
  try:
      logger.info("üöÄ Initializing AI agents...")
      
      # Initialize GroqClient first
      client = GroqClient()
      
      # Initialize PDF processor (always available)
      pdf_processor = EnhancedPDFProcessor()
      logger.info("‚úÖ PDF processor initialized")
      
      # Try to initialize AI components
      try:
          summary_agent = SummaryAgent(client)
          flashcard_agent = FlashcardAgent(client)
          quiz_agent = QuizAgent(client)
          research_agent = AIEnhancedResearchDiscoveryAgent(client)
          youtube_agent = AIEnhancedYouTubeDiscoveryAgent(client)
          web_agent = AIEnhancedWebResourceAgent(client)
          coordinator_agent = AIPresentationCoordinatorAgent(client)
          logger.info("‚úÖ AI agents initialized")
          
          # Check API status
          if check_api_status():
              logger.info("‚úÖ Groq API connection successful")
          else:
              logger.warning("‚ö†Ô∏è Groq API issues detected - fallback mode enabled")
              
      except Exception as e:
          logger.error(f"‚ùå Error initializing AI agents: {e}")
          logger.info("üîÑ Running in fallback mode - basic functionality only")
          
  except Exception as e:
      logger.error(f"‚ùå Critical error during startup: {e}")
      # Don't raise - allow server to start in fallback mode

@app.get("/")
async def root():
  return {"message": "AI Study Assistant API", "version": "1.0.0", "status": "running"}

@app.get("/api-status", response_model=ApiStatusResponse)
async def get_api_status():
  """Get current API status"""
  is_available = check_api_status()
  
  if api_status["quota_exceeded"]:
      status_msg = "Quota exceeded"
      quota_status = "exceeded"
  elif not is_available:
      status_msg = "API unavailable"
      quota_status = "unavailable"
  else:
      status_msg = "API operational"
      quota_status = "available"
  
  return ApiStatusResponse(
      api_available=is_available,
      quota_status=quota_status,
      message=status_msg,
      fallback_enabled=True
  )

@app.get("/health")
async def health_check():
  """Enhanced health check"""
  is_api_available = check_api_status()
  
  health_status = {
      "status": "healthy",
      "pdf_processor": pdf_processor is not None,
      "ai_agents_initialized": all([
          summary_agent, flashcard_agent, quiz_agent, 
          research_agent, youtube_agent, web_agent, coordinator_agent # Include new agent
      ]),
      "groq_api_available": is_api_available,
      "groq_key_configured": bool(os.getenv("GROQ_API_KEY")),
      "fallback_mode": not is_api_available,
      "active_sessions": len(study_sessions),
      "consecutive_api_failures": api_status["consecutive_failures"]
  }
  
  return health_status

@app.post("/upload-pdf", response_model=ProcessingStatus)
async def upload_pdf(file: UploadFile = File(...)):
  """Upload and process PDF file - This works without AI"""
  
  if not file.filename:
      raise HTTPException(status_code=400, detail="No filename provided")
  
  if not file.filename.lower().endswith('.pdf'):
      raise HTTPException(status_code=400, detail="Only PDF files are allowed")
  
  # Check file size (limit to 50MB)
  content = await file.read()
  file_size = len(content)
  
  if file_size > 50 * 1024 * 1024:  # 50MB limit
      raise HTTPException(status_code=400, detail="File too large. Maximum size is 50MB")
  
  if file_size == 0:
      raise HTTPException(status_code=400, detail="Empty file uploaded")
  
  temp_file_path = None
  
  try:
      logger.info(f"üìÑ Processing PDF: {file.filename} ({file_size/1024/1024:.2f}MB)")
      
      # Create temporary file
      with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
          temp_file.write(content)
          temp_file_path = temp_file.name
      
      # Process PDF with timeout handling
      try:
          result = await asyncio.wait_for(
              asyncio.to_thread(pdf_processor.extract_text_with_ocr, temp_file_path),
              timeout=120.0  # 2 minutes timeout
          )
      except asyncio.TimeoutError:
          logger.error("‚ùå PDF processing timeout")
          raise HTTPException(status_code=408, detail="PDF processing timeout. File may be too complex or large.")
      
      if result["status"] == "error":
          logger.error(f"‚ùå PDF processing failed: {result['message']}")
          raise HTTPException(status_code=400, detail=result["message"])
      
      if result["word_count"] < 10:
          logger.warning("‚ö†Ô∏è Very little text extracted from PDF")
          raise HTTPException(
              status_code=422, 
              detail="Very little text could be extracted. PDF may be image-based, protected, or corrupted."
          )
      
      # Store session data
      session_id = "default"
      study_sessions[session_id] = {
          "text": result["text"],
          "file_info": f"File: {file.filename} ({file_size/1024/1024:.2f} MB)",
          "processing_result": result,
          "filename": file.filename
      }
      
      logger.info(f"‚úÖ PDF processed successfully: {result['word_count']} words extracted")
      
      return ProcessingStatus(
          status=result["status"],
          message=result["message"],
          word_count=result["word_count"],
          page_count=result["page_count"],
          methods_used=result["methods_used"]
      )
  
  except HTTPException:
      raise
  except Exception as e:
      logger.error(f"‚ùå Unexpected error processing PDF: {str(e)}")
      raise HTTPException(status_code=500, detail=f"Processing failed: {str(e)}")
  
  finally:
      # Clean up temp file
      if temp_file_path and os.path.exists(temp_file_path):
          try:
              os.unlink(temp_file_path)
          except Exception as e:
              logger.warning(f"‚ö†Ô∏è Failed to cleanup temp file: {e}")

@app.post("/generate-summary", response_model=SummaryResponse)
async def generate_summary(session_id: str = "default"):
  """Generate summary with fallback support"""
  
  if session_id not in study_sessions:
      raise HTTPException(status_code=404, detail="No document found. Please upload a PDF first.")
  
  text = study_sessions[session_id]["text"]
  is_api_available = check_api_status()
  
  try:
      if is_api_available and summary_agent:
          logger.info("üìù Generating AI summary...")
          
          # Limit text length for faster processing
          max_chars = 8000
          if len(text) > max_chars:
              text = text[:max_chars] + "..."
              logger.info(f"üìù Text truncated to {max_chars} characters for faster processing")
          
          # Generate summary with timeout
          summary = await asyncio.wait_for(
              asyncio.to_thread(summary_agent.generate_summary, text),
              timeout=90.0
          )
          
          if summary.startswith("‚ùå"):
              # AI failed, use fallback
              logger.warning("AI summary failed, using fallback")
              summary = generate_fallback_summary(text)
              return SummaryResponse(summary=summary, status="success", fallback_used=True)
          
          logger.info("‚úÖ AI summary generated successfully")
          return SummaryResponse(summary=summary, status="success", fallback_used=False)
      
      else:
          # Use fallback mode
          logger.info("üìù Generating fallback summary (API unavailable)...")
          summary = generate_fallback_summary(text)
          return SummaryResponse(summary=summary, status="success", fallback_used=True)
  
  except asyncio.TimeoutError:
      logger.error("‚ùå Summary generation timeout, using fallback")
      summary = generate_fallback_summary(text)
      return SummaryResponse(summary=summary, status="success", fallback_used=True)
  except Exception as e:
      logger.error(f"‚ùå Summary generation error: {str(e)}, using fallback")
      summary = generate_fallback_summary(text)
      return SummaryResponse(summary=summary, status="success", fallback_used=True)

@app.post("/generate-flashcards", response_model=FlashcardResponse)
async def generate_flashcards(session_id: str = "default", num_cards: int = 10):
  """Generate flashcards with fallback support"""
  
  if session_id not in study_sessions:
      raise HTTPException(status_code=404, detail="No document found. Please upload a PDF first.")
  
  if num_cards < 1 or num_cards > 20:
      num_cards = min(max(num_cards, 1), 20)
  
  text = study_sessions[session_id]["text"]
  is_api_available = check_api_status()
  
  try:
      if is_api_available and flashcard_agent:
          logger.info(f"üÉè Generating {num_cards} AI flashcards...")
          
          # Limit text length for faster processing
          max_chars = 6000
          if len(text) > max_chars:
              text = text[:max_chars] + "..."
          
          # Generate flashcards with timeout
          flashcards = await asyncio.wait_for(
              asyncio.to_thread(flashcard_agent.generate_flashcards_structured, text, num_cards),
              timeout=120.0
          )
          
          if not flashcards:
              # AI failed, use fallback
              logger.warning("AI flashcard generation failed, using fallback")
              flashcards = generate_fallback_flashcards(text, num_cards)
              return FlashcardResponse(flashcards=flashcards, count=len(flashcards), status="success", fallback_used=True)
          
          logger.info(f"‚úÖ Generated {len(flashcards)} AI flashcards successfully")
          return FlashcardResponse(flashcards=flashcards, count=len(flashcards), status="success", fallback_used=False)
      
      else:
          # Use fallback mode
          logger.info(f"üÉè Generating {num_cards} fallback flashcards (API unavailable)...")
          flashcards = generate_fallback_flashcards(text, num_cards)
          return FlashcardResponse(flashcards=flashcards, count=len(flashcards), status="success", fallback_used=True)
  
  except asyncio.TimeoutError:
      logger.error("‚ùå Flashcard generation timeout, using fallback")
      flashcards = generate_fallback_flashcards(text, num_cards)
      return FlashcardResponse(flashcards=flashcards, count=len(flashcards), status="success", fallback_used=True)
  except Exception as e:
      logger.error(f"‚ùå Flashcard generation error: {str(e)}, using fallback")
      flashcards = generate_fallback_flashcards(text, num_cards)
      return FlashcardResponse(flashcards=flashcards, count=len(flashcards), status="success", fallback_used=True)

@app.post("/generate-quiz", response_model=QuizResponse)
async def generate_quiz(session_id: str = "default", num_questions: int = 8):
  """Generate quiz with fallback support"""
  
  if session_id not in study_sessions:
      raise HTTPException(status_code=404, detail="No document found. Please upload a PDF first.")
  
  if num_questions < 1 or num_questions > 15:
      num_questions = min(max(num_questions, 1), 15)
  
  text = study_sessions[session_id]["text"]
  is_api_available = check_api_status()
  
  try:
      if is_api_available and quiz_agent:
          logger.info(f"üìù Generating {num_questions} AI quiz questions...")
          
          # Limit text length for faster processing
          max_chars = 6000
          if len(text) > max_chars:
              text = text[:max_chars] + "..."
          
          # Generate quiz with timeout
          quiz = await asyncio.wait_for(
              asyncio.to_thread(quiz_agent.generate_quiz_structured, text, num_questions),
              timeout=120.0
          )
          
          if not quiz:
              # AI failed, use fallback
              logger.warning("AI quiz generation failed, using fallback")
              quiz = generate_fallback_quiz(text, num_questions)
              return QuizResponse(quiz=quiz, count=len(quiz), status="success", fallback_used=True)
          
          logger.info(f"‚úÖ Generated {len(quiz)} AI quiz questions successfully")
          return QuizResponse(quiz=quiz, count=len(quiz), status="success", fallback_used=False)
      
      else:
          # Use fallback mode
          logger.info(f"üìù Generating {num_questions} fallback quiz questions (API unavailable)...")
          quiz = generate_fallback_quiz(text, num_questions)
          return QuizResponse(quiz=quiz, count=len(quiz), status="success", fallback_used=True)
  
  except asyncio.TimeoutError:
      logger.error("‚ùå Quiz generation timeout, using fallback")
      quiz = generate_fallback_quiz(text, num_questions)
      return QuizResponse(quiz=quiz, count=len(quiz), status="success", fallback_used=True)
  except Exception as e:
      logger.error(f"‚ùå Quiz generation error: {str(e)}, using fallback")
      quiz = generate_fallback_quiz(text, num_questions)
      return QuizResponse(quiz=quiz, count=len(quiz), status="success", fallback_used=True)

@app.post("/discover-research", response_model=ResearchPapersResponse)
async def discover_research(session_id: str = "default", max_papers: int = 10):
  """Discover research papers - works without AI quota"""
  
  if session_id not in study_sessions:
      raise HTTPException(status_code=404, detail="No document found. Please upload a PDF first.")
  
  if max_papers > 15:
      max_papers = 15
  
  try:
      logger.info("üîç Discovering research papers...")
      text = study_sessions[session_id]["text"]
      
      # This can work even with quota issues since it mainly uses web search
      papers = await asyncio.wait_for(
          asyncio.to_thread(research_agent.find_papers, text, max_papers),
          timeout=180.0
      )
      
      logger.info(f"‚úÖ Found {len(papers)} research papers")
      return ResearchPapersResponse(papers=papers, count=len(papers), status="success")
  
  except asyncio.TimeoutError:
      logger.error("‚ùå Research discovery timeout")
      return ResearchPapersResponse(papers=[], count=0, status="success")
  except Exception as e:
      logger.error(f"‚ùå Research discovery error: {str(e)}")
      return ResearchPapersResponse(papers=[], count=0, status="success")

# REPLACE your /discover-videos endpoint in fastapi_backend.py with this:

@app.post("/discover-videos", response_model=VideosResponse)
async def discover_videos(session_id: str = "default", max_videos: int = 10):
    """Discover YouTube videos - FIXED VERSION"""
    
    if session_id not in study_sessions:
        raise HTTPException(status_code=404, detail="No document found. Please upload a PDF first.")
    
    if max_videos > 12:
        max_videos = 12
    
    try:
        logger.info("üé• Starting video discovery...")
        text = study_sessions[session_id]["text"]
        
        # Extract keywords with better fallback
        try:
            if check_api_status() and research_agent:
                topic, research_keywords, all_keywords = await asyncio.wait_for(
                    asyncio.to_thread(research_agent.extract_smart_keywords_and_topic, text),
                    timeout=30.0
                )
            else:
                # Improved fallback keyword extraction
                topic, research_keywords = extract_keywords_fallback(text)
        except Exception as e:
            logger.warning(f"Keyword extraction failed: {e}, using basic fallback")
            topic, research_keywords = extract_keywords_fallback(text)
        
        logger.info(f"üîç Topic: {topic}, Keywords: {research_keywords[:3]}")
        
        # FIXED: Call find_videos with correct parameters (keywords, topic, max_videos)
        videos = await asyncio.wait_for(
            asyncio.to_thread(youtube_agent.find_videos, research_keywords, topic, max_videos),
            timeout=120.0
        )
        
        logger.info(f"‚úÖ Found {len(videos)} educational videos")
        return VideosResponse(videos=videos, count=len(videos), status="success")
    
    except asyncio.TimeoutError:
        logger.error("‚ùå Video discovery timeout")
        # Return placeholder videos instead of empty list
        placeholder_videos = generate_placeholder_videos(text, max_videos)
        return VideosResponse(videos=placeholder_videos, count=len(placeholder_videos), status="success")
    except Exception as e:
        logger.error(f"‚ùå Video discovery error: {str(e)}")
        # Return placeholder videos instead of empty list
        placeholder_videos = generate_placeholder_videos(text, max_videos)
        return VideosResponse(videos=placeholder_videos, count=len(placeholder_videos), status="success")

# ADD these helper functions to your fastapi_backend.py:

def extract_keywords_fallback(text: str) -> tuple:
    """Improved fallback keyword extraction"""
    if not text.strip():
        return "Study Material", ["education", "tutorial", "course"]
    
    # Get first 500 words for analysis
    words = text.split()[:500]
    text_sample = ' '.join(words)
    
    # Simple frequency analysis
    word_freq = {}
    common_words = {"the", "and", "or", "but", "in", "on", "at", "to", "for", "of", "with", "by", "is", "are", "was", "were", "be", "been", "have", "has", "had", "do", "does", "did", "will", "would", "could", "should", "may", "might", "can", "cannot", "a", "an", "this", "that", "these", "those"}
    
    for word in words:
        clean_word = word.lower().strip('.,!?;:"()[]{}')
        if len(clean_word) > 3 and clean_word not in common_words and clean_word.isalpha():
            word_freq[clean_word] = word_freq.get(clean_word, 0) + 1
    
    # Get most frequent meaningful words
    keywords = sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True)[:8]
    
    # Determine topic from keywords
    if keywords:
        topic = keywords[0].title()
    else:
        topic = "Educational Content"
        keywords = ["education", "tutorial", "learning"]
    
    return topic, keywords

def generate_placeholder_videos(text: str, max_videos: int) -> List[Dict]:
    """Generate placeholder videos when discovery fails"""
    topic, keywords = extract_keywords_fallback(text)
    
    placeholders = []
    for i in range(min(max_videos, 5)):
        keyword = keywords[i % len(keywords)] if keywords else "education"
        placeholders.append({
            'title': f"Educational Video: {keyword.title()} Tutorial",
            'channel': "Educational Channel",
            'description': f"Comprehensive tutorial covering {keyword} concepts and applications. Perfect for students and professionals.",
            'url': "https://youtu.be/placeholder",
            'published_at': "2024-01-01T00:00:00Z",
            'thumbnail': "",
            'duration': "15:30",
            'views': "10K views",
            'educational_score': 'Placeholder',
            'source': 'placeholder'
        })
    
    return placeholders


# REPLACE your /discover-resources endpoint in fastapi_backend.py with this:

@app.post("/discover-resources", response_model=WebResourcesResponse)
async def discover_resources(session_id: str = "default", max_resources: int = 12):
    """Discover web resources - FIXED VERSION"""
    
    if session_id not in study_sessions:
        raise HTTPException(status_code=404, detail="No document found. Please upload a PDF first.")
    
    if max_resources > 15:
        max_resources = 15
    
    try:
        logger.info("üåê Discovering web resources...")
        text = study_sessions[session_id]["text"]
        
        # Extract keywords with fallback
        try:
            if check_api_status() and research_agent:
                topic, research_keywords, all_keywords = await asyncio.wait_for(
                    asyncio.to_thread(research_agent.extract_smart_keywords_and_topic, text),
                    timeout=30.0
                )
            else:
                # Fallback keyword extraction
                topic, research_keywords = extract_keywords_fallback(text)
        except Exception as e:
            logger.warning(f"Keyword extraction failed: {e}, using basic fallback")
            topic, research_keywords = extract_keywords_fallback(text)
        
        logger.info(f"üîç Topic: {topic}, Keywords: {research_keywords[:3]}")
        
        # FIXED: Call find_resources with correct parameters (keywords, topic, max_resources)
        resources = await asyncio.wait_for(
            asyncio.to_thread(web_agent.find_resources, research_keywords, topic, max_resources),
            timeout=150.0
        )
        
        logger.info(f"‚úÖ Found {len(resources)} web resources")
        return WebResourcesResponse(resources=resources, count=len(resources), status="success")
    
    except asyncio.TimeoutError:
        logger.error("‚ùå Resource discovery timeout")
        # Return placeholder resources instead of empty list
        placeholder_resources = generate_placeholder_resources(text, max_resources)
        return WebResourcesResponse(resources=placeholder_resources, count=len(placeholder_resources), status="success")
    except Exception as e:
        logger.error(f"‚ùå Resource discovery error: {str(e)}")
        # Return placeholder resources instead of empty list
        placeholder_resources = generate_placeholder_resources(text, max_resources)
        return WebResourcesResponse(resources=placeholder_resources, count=len(placeholder_resources), status="success")

# ADD this helper function to your fastapi_backend.py:

def generate_placeholder_resources(text: str, max_resources: int) -> List[Dict]:
    """Generate placeholder resources when discovery fails"""
    topic, keywords = extract_keywords_fallback(text)
    
    placeholders = []
    for i in range(min(max_resources, 6)):
        keyword = keywords[i % len(keywords)] if keywords else "education"
        placeholders.append({
            'title': f"{keyword.title()} Learning Resource",
            'type': 'Educational Resource',
            'source': 'Learning Platform',
            'description': f"Comprehensive learning resource covering {keyword} concepts, applications, and best practices. Includes tutorials, examples, and exercises.",
            'url': f"https://example-learning.com/{keyword.lower()}",
            'quality_score': 'Good'
        })
    
    return placeholders


@app.post("/ask-question", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
  """Answer questions with fallback support"""
  
  if not request.question.strip():
      raise HTTPException(status_code=400, detail="Question cannot be empty")
  
  if not request.document_text.strip():
      raise HTTPException(status_code=400, detail="No document text provided")
  
  is_api_available = check_api_status()
  
  try:
      if is_api_available and client:
          logger.info(f"‚ùì Answering question with AI: {request.question[:50]}...")
          
          # Limit text for analysis
          max_chars = 6000
          text_content = request.document_text[:max_chars]
          if len(request.document_text) > max_chars:
              text_content += "..."

          prompt = f"""Based on the following document content, please answer the question comprehensively and accurately.

Document Content:
{text_content}

Question: {request.question}

Instructions:
- Provide a detailed, accurate answer based on the document
- If the information isn't in the document, say so clearly
- Use specific examples from the document when possible
- Keep the answer well-structured and easy to understand"""

          # Generate answer with timeout
          response = await asyncio.wait_for(
              asyncio.to_thread(client.chat_completion, [{"role": "user", "content": prompt}], None, 800),
              timeout=60.0
          )
          
          if response.startswith("‚ùå"):
              # AI failed, use fallback
              logger.warning("AI question answering failed, using fallback")
              fallback_answer = generate_fallback_answer(request.question, request.document_text)
              return AnswerResponse(answer=fallback_answer, status="success", fallback_used=True)
          
          logger.info("‚úÖ Question answered successfully with AI")
          return AnswerResponse(answer=response, status="success", fallback_used=False)
      
      else:
          # Use fallback mode
          logger.info(f"‚ùì Answering question with fallback: {request.question[:50]}...")
          fallback_answer = generate_fallback_answer(request.question, request.document_text)
          return AnswerResponse(answer=fallback_answer, status="success", fallback_used=True)
  
  except asyncio.TimeoutError:
      logger.error("‚ùå Question answering timeout, using fallback")
      fallback_answer = generate_fallback_answer(request.question, request.document_text)
      return AnswerResponse(answer=fallback_answer, status="success", fallback_used=True)
  except Exception as e:
      logger.error(f"‚ùå Question answering error: {str(e)}, using fallback")
      fallback_answer = generate_fallback_answer(request.question, request.document_text)
      return AnswerResponse(answer=fallback_answer, status="success", fallback_used=True)

def generate_fallback_answer(question: str, document_text: str) -> str:
  """Generate a basic answer without AI when quota is exceeded"""
  if not question.strip() or not document_text.strip():
      return "I need both a question and document content to provide an answer."
  
  # Simple keyword matching approach
  question_lower = question.lower()
  doc_lower = document_text.lower()
  
  # Find sentences containing question keywords
  question_words = [word for word in question_lower.split() if len(word) > 3]
  sentences = [s.strip() for s in document_text.split('.') if len(s.strip()) > 20]
  
  relevant_sentences = []
  for sentence in sentences:
      sentence_lower = sentence.lower()
      word_matches = sum(1 for word in question_words if word in sentence_lower)
      if word_matches >= 1:  # At least one keyword match
          relevant_sentences.append((sentence, word_matches))
  
  # Sort by relevance (number of matching keywords)
  relevant_sentences.sort(key=lambda x: x[1], reverse=True)
  
  if relevant_sentences:
      answer = f"""Based on the document content, here's what I found related to your question:

**Question:** {question}

**Relevant information from the document:**

{relevant_sentences[0][0]}"""

      # Add additional relevant sentences if available
      if len(relevant_sentences) > 1:
          answer += f"\n\n**Additional context:**\n\n{relevant_sentences[1][0]}"
      
      if len(relevant_sentences) > 2:
          answer += f"\n\n{relevant_sentences[2][0]}"
      
      answer += f"""

**Note:** This answer was generated using basic text matching due to AI service limitations. For more detailed analysis, please try again later when the AI service is available.

**Suggestion:** You can search the document for keywords related to your question: {', '.join(question_words[:5])}"""
      
      return answer
  else:
      return f"""I couldn't find specific information related to your question "{question}" in the document using basic text matching.

**Suggestions:**
1. Try rephrasing your question with different keywords
2. Check if the information might be expressed differently in the document
3. Browse through the document manually for related concepts

**Question keywords searched:** {', '.join(question_words[:5])}

**Note:** This search was performed using basic text matching due to AI service limitations. For more sophisticated analysis, please try again later when the AI service is available."""

@app.delete("/clear-session")
async def clear_session(session_id: str = "default"):
  """Clear session data"""
  
  if session_id in study_sessions:
      del study_sessions[session_id]
      logger.info(f"üóëÔ∏è Cleared session: {session_id}")
      return {"message": "Session cleared successfully", "status": "success"}
  else:
      return {"message": "No active session found", "status": "info"}

@app.get("/session-info")
async def get_session_info(session_id: str = "default"):
  """Get information about current session"""
  
  if session_id not in study_sessions:
      return {"active": False, "message": "No active session"}
  
  session_data = study_sessions[session_id]
  is_api_available = check_api_status()
  
  return {
      "active": True,
      "file_info": session_data.get("file_info", ""),
      "filename": session_data.get("filename", ""),
      "word_count": session_data.get("processing_result", {}).get("word_count", 0),
      "page_count": session_data.get("processing_result", {}).get("page_count", 0),
      "methods_used": session_data.get("processing_result", {}).get("methods_used", []),
      "api_status": {
          "available": is_api_available,
          "fallback_mode": not is_api_available,
          "quota_exceeded": api_status["quota_exceeded"]
      }
  }

@app.post("/check-quota")
async def check_quota_endpoint():
  """Endpoint to manually check API quota status"""
  is_available = check_api_status()
  
  return {
      "api_available": is_available,
      "quota_exceeded": api_status["quota_exceeded"],
      "consecutive_failures": api_status["consecutive_failures"],
      "last_check": api_status["last_check"],
      "message": "API operational" if is_available else "API unavailable - using fallback mode",
      "fallback_features": [
          "Basic PDF text extraction",
          "Simple summary generation", 
          "Basic flashcard creation",
          "Simple quiz generation",
          "Keyword-based question answering",
          "Web resource discovery",
          "Video discovery"
      ]
  }

@app.post("/generate-presentation", response_model=GeneratePresentationOutput)
async def generate_presentation(request: GeneratePresentationRequest):
  """API endpoint to generate a presentation using the multi-agent system."""
  try:
      if not coordinator_agent:
          raise HTTPException(status_code=500, detail="Coordinator agent not initialized.")

      logger.info(f"üöÄ Generating presentation for topic: {request.topic}")
      
      presentation, design_guidelines, quality_result = await asyncio.to_thread(
          coordinator_agent.create_presentation,
          topic=request.topic,
          audience=request.audience,
          duration=request.duration,
          theme=request.theme
      )
      
      response_data = GeneratePresentationOutput(
          success=True,
          presentation=PresentationResponse(
              title=presentation.title,
              slides=[
                  SlideContentResponse(
                      title=slide.title,
                      content=slide.content,
                      slide_type=slide.slide_type,
                      notes=slide.notes
                  ) for slide in presentation.slides
              ],
              total_slides=presentation.total_slides,
              theme=presentation.theme
          ),
          design_guidelines=DesignGuidelinesResponse(
              color_scheme=design_guidelines["color_scheme"],
              fonts=design_guidelines["fonts"],
              layout=design_guidelines["layout"],
              suggestions=design_guidelines["suggestions"]
          ),
          quality_assessment=QualityAssessmentResponse(
              issues=quality_result["issues"],
              suggestions=quality_result["suggestions"],
              quality_assessment=quality_result["quality_assessment"],
              overall_score=quality_result["overall_score"],
              success=quality_result["success"]
          )
      )
      
      logger.info(f"‚úÖ Presentation generated successfully for topic: {request.topic}")
      return response_data
  
  except Exception as e:
      logger.error(f"‚ùå Error generating presentation: {str(e)}")
      raise HTTPException(status_code=500, detail=f"Failed to create presentation: {str(e)}")


if __name__ == "__main__":
  import uvicorn
  print("üöÄ Starting AI Study Assistant API with Groq Integration...")
  print("üì± API will be available at: http://localhost:8000")
  print("üìö API Documentation: http://localhost:8000/docs")
  print("üîç Interactive API: http://localhost:8000/redoc")
  print("üí° Features work with or without Groq API quota!")
  
  uvicorn.run(
      "fastapi_backend:app",
      host="0.0.0.0",
      port=8000,
      reload=True,
      log_level="info"
  )
